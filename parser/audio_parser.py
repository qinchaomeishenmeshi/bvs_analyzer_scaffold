import os
import json
from pathlib import Path
from typing import Dict, List, Optional
import whisper
import ffmpeg
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn


class AudioParser:
    """
    éŸ³é¢‘è§£æå™¨ï¼Œè´Ÿè´£ä»è§†é¢‘ä¸­æå–éŸ³é¢‘å¹¶è¿›è¡Œè¯­éŸ³è½¬å†™
    """
    
    def __init__(self, console: Console = None, model_size: str = "base"):
        """
        åˆå§‹åŒ–éŸ³é¢‘è§£æå™¨
        :param console: Rich Consoleå¯¹è±¡
        :param model_size: Whisperæ¨¡å‹å¤§å° (tiny, base, small, medium, large)
        """
        self.console = console or Console()
        self.model_size = model_size
        self.model = None
        self.audio_output_dir = None
        self.transcript_output_dir = None
        self._load_whisper_model()
    
    def configure(self, audio_output_dir: str = None, transcript_output_dir: str = None):
        """
        é…ç½®è¾“å‡ºç›®å½•
        :param audio_output_dir: éŸ³é¢‘è¾“å‡ºç›®å½•
        :param transcript_output_dir: è½¬å†™æ–‡æœ¬è¾“å‡ºç›®å½•
        """
        if audio_output_dir:
            self.audio_output_dir = Path(audio_output_dir)
            self.audio_output_dir.mkdir(parents=True, exist_ok=True)
        
        if transcript_output_dir:
            self.transcript_output_dir = Path(transcript_output_dir)
            self.transcript_output_dir.mkdir(parents=True, exist_ok=True)
    
    def _load_whisper_model(self):
        """
        åŠ è½½ Whisper æ¨¡å‹
        """
        try:
            self.console.print(f"[cyan]ğŸ¤– æ­£åœ¨åŠ è½½ Whisper {self.model_size} æ¨¡å‹...[/]")
            self.model = whisper.load_model(self.model_size)
            self.console.print(f"[green]âœ… Whisper æ¨¡å‹åŠ è½½æˆåŠŸ[/]")
        except Exception as e:
            self.console.print(f"[red]âŒ Whisper æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}[/]")
            raise e
    
    def extract_audio_from_video(self, video_path: str, audio_path: str = None) -> str:
        """
        ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘
        :param video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        :param audio_path: éŸ³é¢‘è¾“å‡ºè·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        :return: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        video_path = Path(video_path)
        
        if audio_path is None:
            audio_path = video_path.parent / f"{video_path.stem}_audio.wav"
        else:
            audio_path = Path(audio_path)
        
        try:
            self.console.print(f"[cyan]ğŸµ æ­£åœ¨æå–éŸ³é¢‘: {video_path.name}[/]")
            
            # ä½¿ç”¨ ffmpeg æå–éŸ³é¢‘
            (
                ffmpeg
                .input(str(video_path))
                .output(str(audio_path), acodec='pcm_s16le', ac=1, ar='16000')
                .overwrite_output()
                .run(quiet=True)
            )
            
            self.console.print(f"[green]âœ… éŸ³é¢‘æå–å®Œæˆ: {audio_path.name}[/]")
            return str(audio_path)
            
        except Exception as e:
            self.console.print(f"[red]âŒ éŸ³é¢‘æå–å¤±è´¥: {str(e)}[/]")
            raise e
    
    def transcribe_audio(self, audio_path: str, language: str = "zh") -> Dict:
        """
        ä½¿ç”¨ Whisper è½¬å†™éŸ³é¢‘ä¸ºæ–‡æœ¬
        :param audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :param language: è¯­è¨€ä»£ç  (zh, en, etc.)
        :return: è½¬å†™ç»“æœå­—å…¸
        """
        try:
            self.console.print(f"[cyan]ğŸ“ æ­£åœ¨è½¬å†™éŸ³é¢‘: {Path(audio_path).name}[/]")
            
            # ä½¿ç”¨ Whisper è¿›è¡Œè½¬å†™
            result = self.model.transcribe(
                audio_path,
                language=language,
                word_timestamps=True,
                verbose=False
            )
            
            # å¤„ç†è½¬å†™ç»“æœ
            segments = []
            for segment in result['segments']:
                segments.append({
                    'start': segment['start'],
                    'end': segment['end'],
                    'text': segment['text'].strip(),
                    'words': segment.get('words', [])
                })
            
            transcription_result = {
                'text': result['text'].strip(),
                'language': result['language'],
                'segments': segments,
                'duration': segments[-1]['end'] if segments else 0
            }
            
            self.console.print(f"[green]âœ… éŸ³é¢‘è½¬å†™å®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ[/]")
            return transcription_result
            
        except Exception as e:
            self.console.print(f"[red]âŒ éŸ³é¢‘è½¬å†™å¤±è´¥: {str(e)}[/]")
            raise e
    
    def process_video(self, video_path: str, output_dir: str = None) -> Dict:
        """
        å¤„ç†è§†é¢‘æ–‡ä»¶ï¼šæå–éŸ³é¢‘ + è½¬å†™æ–‡æœ¬
        :param video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        :param output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨è§†é¢‘æ‰€åœ¨ç›®å½•
        :return: å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        video_path = Path(video_path)
        
        if output_dir is None:
            output_dir = video_path.parent
        else:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # 1. æå–éŸ³é¢‘
            audio_path = output_dir / f"{video_path.stem}_audio.wav"
            self.extract_audio_from_video(str(video_path), str(audio_path))
            
            # 2. è½¬å†™éŸ³é¢‘
            transcription = self.transcribe_audio(str(audio_path))
            
            # 3. ä¿å­˜è½¬å†™ç»“æœ
            transcript_path = output_dir / f"{video_path.stem}_transcript.json"
            with open(transcript_path, 'w', encoding='utf-8') as f:
                json.dump(transcription, f, ensure_ascii=False, indent=2)
            
            # 4. ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
            srt_path = output_dir / f"{video_path.stem}_subtitles.srt"
            self._save_as_srt(transcription['segments'], str(srt_path))
            
            result = {
                'video_path': str(video_path),
                'audio_path': str(audio_path),
                'transcript_path': str(transcript_path),
                'srt_path': str(srt_path),
                'transcription': transcription
            }
            
            self.console.print(f"[green]ğŸ‰ è§†é¢‘å¤„ç†å®Œæˆ: {video_path.name}[/]")
            return result
            
        except Exception as e:
            self.console.print(f"[red]âŒ è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}[/]")
            raise e
    
    def _save_as_srt(self, segments: List[Dict], srt_path: str):
        """
        å°†è½¬å†™ç‰‡æ®µä¿å­˜ä¸º SRT å­—å¹•æ–‡ä»¶
        :param segments: è½¬å†™ç‰‡æ®µåˆ—è¡¨
        :param srt_path: SRTæ–‡ä»¶ä¿å­˜è·¯å¾„
        """
        def format_time(seconds):
            """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼"""
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = int(seconds % 60)
            millisecs = int((seconds % 1) * 1000)
            return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
        
        with open(srt_path, 'w', encoding='utf-8') as f:
            for i, segment in enumerate(segments, 1):
                start_time = format_time(segment['start'])
                end_time = format_time(segment['end'])
                text = segment['text']
                
                f.write(f"{i}\n")
                f.write(f"{start_time} --> {end_time}\n")
                f.write(f"{text}\n\n")
        
        self.console.print(f"[green]ğŸ“„ SRTå­—å¹•æ–‡ä»¶å·²ä¿å­˜: {Path(srt_path).name}[/]")
    
    def transcribe_from_url(self, url: str, save_audio: bool = True, save_transcript: bool = True) -> Optional[Dict]:
        """
        ä»URLç›´æ¥è½¬å†™éŸ³é¢‘ï¼ˆä½¿ç”¨yt-dlpä¸‹è½½éŸ³é¢‘ï¼‰
        :param url: è§†é¢‘URL
        :param save_audio: æ˜¯å¦ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        :param save_transcript: æ˜¯å¦ä¿å­˜è½¬å†™æ–‡ä»¶
        :return: è½¬å†™ç»“æœ
        """
        import yt_dlp
        import tempfile
        
        try:
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)
                
                # é…ç½®yt-dlpé€‰é¡¹ï¼Œåªä¸‹è½½éŸ³é¢‘
                ydl_opts = {
                    'format': 'bestaudio/best',
                    'outtmpl': str(temp_path / '%(title)s.%(ext)s'),
                    'extractaudio': True,
                    'audioformat': 'wav',
                    'quiet': True,
                    'no_warnings': True
                }
                
                self.console.print(f"[cyan]ğŸµ æ­£åœ¨ä»URLæå–éŸ³é¢‘...[/]")
                
                # ä¸‹è½½éŸ³é¢‘
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(url, download=True)
                    
                    # æŸ¥æ‰¾ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶
                    audio_files = list(temp_path.glob("*"))
                    if not audio_files:
                        raise Exception("æœªæ‰¾åˆ°ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶")
                    
                    audio_file = audio_files[0]
                    
                    # è½¬å†™éŸ³é¢‘
                    transcription = self.transcribe_audio(str(audio_file))
                    
                    # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœé…ç½®äº†è¾“å‡ºç›®å½•ï¼‰
                    if save_audio and self.audio_output_dir:
                        saved_audio_path = self.audio_output_dir / f"{info.get('id', 'unknown')}_audio.wav"
                        import shutil
                        shutil.copy2(audio_file, saved_audio_path)
                        transcription['audio_path'] = str(saved_audio_path)
                    
                    if save_transcript and self.transcript_output_dir:
                        transcript_path = self.transcript_output_dir / f"{info.get('id', 'unknown')}_transcript.json"
                        with open(transcript_path, 'w', encoding='utf-8') as f:
                            json.dump(transcription, f, ensure_ascii=False, indent=2)
                        transcription['transcript_path'] = str(transcript_path)
                    
                    return transcription
                    
        except Exception as e:
            self.console.print(f"[red]âŒ URLéŸ³é¢‘è½¬å†™å¤±è´¥: {str(e)}[/]")
            return None
    
    def batch_process_videos(self, video_paths: List[str], output_dir: str = None) -> List[Dict]:
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘æ–‡ä»¶
        :param video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        :param output_dir: è¾“å‡ºç›®å½•
        :return: å¤„ç†ç»“æœåˆ—è¡¨
        """
        results = []
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=self.console
        ) as progress:
            task = progress.add_task("[cyan]æ‰¹é‡å¤„ç†è§†é¢‘", total=len(video_paths))
            
            for i, video_path in enumerate(video_paths):
                progress.update(task, description=f"[cyan]å¤„ç†ç¬¬ {i+1}/{len(video_paths)} ä¸ªè§†é¢‘")
                try:
                    result = self.process_video(video_path, output_dir)
                    results.append(result)
                except Exception as e:
                    self.console.print(f"[red]âŒ å¤„ç†è§†é¢‘å¤±è´¥ {video_path}: {str(e)}[/]")
                progress.advance(task)
        
        self.console.print(f"[green]âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(results)}/{len(video_paths)} ä¸ªè§†é¢‘[/]")
        return results